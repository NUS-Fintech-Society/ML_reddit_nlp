{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme = pd.read_csv('../data_cleaned/meme_stocks.csv').drop('Unnamed: 0',axis=1)\n",
    "top = pd.read_csv('../data_cleaned/top_companies.csv').drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_stock_from_csv(df:pd.DataFrame,stock:str,datalist=[])-> pd.DataFrame:\n",
    "    try:\n",
    "        if len(datalist) ==0:\n",
    "            return df[df['tic']==stock]\n",
    "        else: \n",
    "            return df[df['tic']==stock][datalist]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Data for {stock} is missing')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "amc = select_stock_from_csv(meme,'AMC',['date','close','volume','tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "amc['pct_chng'] = amc['close'].pct_change().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "amc['movement'] = amc.apply(lambda x: 1 if x['pct_chng'] > 0 else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>pct_chng</th>\n",
       "      <th>movement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>18.900267</td>\n",
       "      <td>420900</td>\n",
       "      <td>AMC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>18.413568</td>\n",
       "      <td>246500</td>\n",
       "      <td>AMC</td>\n",
       "      <td>-0.025751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>18.561052</td>\n",
       "      <td>271500</td>\n",
       "      <td>AMC</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>18.863400</td>\n",
       "      <td>175400</td>\n",
       "      <td>AMC</td>\n",
       "      <td>0.016289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>19.047752</td>\n",
       "      <td>192800</td>\n",
       "      <td>AMC</td>\n",
       "      <td>0.009773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>2021-08-23</td>\n",
       "      <td>36.779999</td>\n",
       "      <td>75319300</td>\n",
       "      <td>AMC</td>\n",
       "      <td>0.068875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>2021-08-24</td>\n",
       "      <td>44.259998</td>\n",
       "      <td>228489600</td>\n",
       "      <td>AMC</td>\n",
       "      <td>0.203371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>43.959999</td>\n",
       "      <td>209271500</td>\n",
       "      <td>AMC</td>\n",
       "      <td>-0.006778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>2021-08-26</td>\n",
       "      <td>40.310001</td>\n",
       "      <td>109710200</td>\n",
       "      <td>AMC</td>\n",
       "      <td>-0.083030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>40.840000</td>\n",
       "      <td>72317700</td>\n",
       "      <td>AMC</td>\n",
       "      <td>0.013148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1676 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      close     volume  tic  pct_chng  movement\n",
       "0     2015-01-02  18.900267     420900  AMC  0.000000         0\n",
       "2     2015-01-05  18.413568     246500  AMC -0.025751         0\n",
       "4     2015-01-06  18.561052     271500  AMC  0.008010         1\n",
       "6     2015-01-07  18.863400     175400  AMC  0.016289         1\n",
       "8     2015-01-08  19.047752     192800  AMC  0.009773         1\n",
       "...          ...        ...        ...  ...       ...       ...\n",
       "3974  2021-08-23  36.779999   75319300  AMC  0.068875         1\n",
       "3979  2021-08-24  44.259998  228489600  AMC  0.203371         1\n",
       "3984  2021-08-25  43.959999  209271500  AMC -0.006778         0\n",
       "3989  2021-08-26  40.310001  109710200  AMC -0.083030         0\n",
       "3994  2021-08-27  40.840000   72317700  AMC  0.013148         1\n",
       "\n",
       "[1676 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_20150101 = pd.read_csv('../data/Reddit Data/2015/Reddit_Comment_2015-01.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_20150101 = reddit_20150101.rename(columns={'Body':'text'})\n",
    "reddit_20150101['label'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_20150101.to_csv('doccano_demo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>Parent</th>\n",
       "      <th>text</th>\n",
       "      <th>Score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-01-01</td>\n",
       "      <td>cnasafn</td>\n",
       "      <td>t1_cnardcl</td>\n",
       "      <td>Absolutely liquidate. Our bank's PB is not in ...</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-01-01</td>\n",
       "      <td>cnase68</td>\n",
       "      <td>t3_2qxx1u</td>\n",
       "      <td>ARCP</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-01-01</td>\n",
       "      <td>cnasd41</td>\n",
       "      <td>t1_cnaqx6u</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-01-01</td>\n",
       "      <td>cnaslz4</td>\n",
       "      <td>t1_cnarxn9</td>\n",
       "      <td>Thanks for the detailed post. Perhaps my tone ...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-01-01</td>\n",
       "      <td>cnasm73</td>\n",
       "      <td>t1_cnal0pd</td>\n",
       "      <td>The messenger used frequently in Asian countries?</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34582</th>\n",
       "      <td>15-01-31</td>\n",
       "      <td>co71c04</td>\n",
       "      <td>t1_co70tmj</td>\n",
       "      <td>I prefer puts too, but in the case of SHAK, th...</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34583</th>\n",
       "      <td>15-01-31</td>\n",
       "      <td>co71cde</td>\n",
       "      <td>t3_2ubj7y</td>\n",
       "      <td>what the fuck?</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34584</th>\n",
       "      <td>15-01-31</td>\n",
       "      <td>co71g4j</td>\n",
       "      <td>t1_co6zv37</td>\n",
       "      <td>problem is, it seems unlikely you're pulling d...</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34585</th>\n",
       "      <td>15-01-31</td>\n",
       "      <td>co71ii6</td>\n",
       "      <td>t1_co6y6d1</td>\n",
       "      <td>This.  You have to go through a brokerage,  mo...</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34586</th>\n",
       "      <td>15-01-31</td>\n",
       "      <td>co71k7y</td>\n",
       "      <td>t1_co710l7</td>\n",
       "      <td>Nonsense! Boom &amp;amp; Bust cycles are a natural...</td>\n",
       "      <td>28</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34587 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       ID      Parent  \\\n",
       "0      15-01-01  cnasafn  t1_cnardcl   \n",
       "1      15-01-01  cnase68   t3_2qxx1u   \n",
       "2      15-01-01  cnasd41  t1_cnaqx6u   \n",
       "3      15-01-01  cnaslz4  t1_cnarxn9   \n",
       "4      15-01-01  cnasm73  t1_cnal0pd   \n",
       "...         ...      ...         ...   \n",
       "34582  15-01-31  co71c04  t1_co70tmj   \n",
       "34583  15-01-31  co71cde   t3_2ubj7y   \n",
       "34584  15-01-31  co71g4j  t1_co6zv37   \n",
       "34585  15-01-31  co71ii6  t1_co6y6d1   \n",
       "34586  15-01-31  co71k7y  t1_co710l7   \n",
       "\n",
       "                                                    text  Score label  \n",
       "0      Absolutely liquidate. Our bank's PB is not in ...      3        \n",
       "1                                                   ARCP      7        \n",
       "2                                              [deleted]      1        \n",
       "3      Thanks for the detailed post. Perhaps my tone ...      1        \n",
       "4      The messenger used frequently in Asian countries?      4        \n",
       "...                                                  ...    ...   ...  \n",
       "34582  I prefer puts too, but in the case of SHAK, th...      2        \n",
       "34583                                     what the fuck?      2        \n",
       "34584  problem is, it seems unlikely you're pulling d...      5        \n",
       "34585  This.  You have to go through a brokerage,  mo...      3        \n",
       "34586  Nonsense! Boom &amp; Bust cycles are a natural...     28        \n",
       "\n",
       "[34587 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Score just means upvotes or downvotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from w3lib.html import replace_entities ## removes html entities\n",
    "import reticker ## extracting tickers\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_ticker(text):\n",
    "    tickers_to_replace = [i if i in tickers['tickered'].to_list() else '' for i in re.findall(r'\\$\\w+',str(text))]\n",
    "    for i in tickers_to_replace:\n",
    "        if i:\n",
    "            name = tickers[' name'].loc[tickers['tickered'] == i].iloc[0]\n",
    "            if name:\n",
    "                text = text.replace(i, f'{name},')\n",
    "            else: \n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    text = re.sub(r'\\$\\w+','', str(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1179"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_20150101.loc[16].Body)#[['Body','Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe create something with a meaningful score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove \\n\\n values\n",
    "## remove &amp;\n",
    "## remove deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = replace_entities(text)\n",
    "    text = re.sub(r'\\n', '',text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'\\[removed\\]', '',text)\n",
    "    text = re.sub(r'\\[deleted\\]', '',text)\n",
    "    text = re.sub(r'/u/', '',text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def generate_tickers(text):\n",
    "    return reticker.TickerExtractor().extract(str(text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_20150101['clean_text'] = reddit_20150101['Body'].apply(clean_text)\n",
    "reddit_20150101['tickers'] = reddit_20150101['Body'].apply(generate_tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create pipeline\n",
    "\n",
    "def merge_and_clean_data(data_folder):\n",
    "    main_folder_list = glob.glob(data_folder + '/*')\n",
    "    final = []\n",
    "    for year_folders in main_folder_list:\n",
    "        csv_list = glob.glob(year_folders + '/*.csv')\n",
    "        for csv in csv_list:\n",
    "            print(f'loading for {csv}...')\n",
    "            if csv.split('_')[1] == 'Submission':\n",
    "                df = pd.read_csv(csv).dropna()\n",
    "                df['Body'] = df.apply(lambda x: str(x['Title']) + str(x['Text']),axis=1)\n",
    "                df['text'] = df['Body'].apply(clean_text)\n",
    "                df['tickers']=df['Body'].apply(generate_tickers)\n",
    "                df=df[['Date','text','Score','tickers']]\n",
    "                df = df[df['tickers'].map(len)!=0]\n",
    "                df = df.rename(columns = {'Date':'date','Score':'score'})\n",
    "                final.append(df)\n",
    "                \n",
    "            if csv.split('_')[1] == 'Comment':\n",
    "                df = pd.read_csv(csv).dropna()\n",
    "                df['text'] = df['Body'].apply(clean_text)\n",
    "                df['tickers']=df['Body'].apply(generate_tickers)\n",
    "                df=df[['Date','text','Score','tickers']]\n",
    "                df = df[df['tickers'].map(len)!=0]\n",
    "                df = df.rename(columns = {'Date':'date','Score':'score'})\n",
    "                final.append(df)\n",
    "            \n",
    "    return pd.concat(final)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/Reddit data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-09.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-08.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-09.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-08.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-06.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-12.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-03.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-02.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-07.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-11.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-05.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-01.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-04.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-10.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-05.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-11.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-10.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-04.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-01.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-03.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-12.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-06.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Submission_2015-07.csv...\n",
      "loading for ../data/Reddit data/2015/Reddit_Comment_2015-02.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-01.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-04.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-10.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-11.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-05.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-02.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-07.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-06.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-12.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-03.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-07.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-02.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-03.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-12.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-06.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-10.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-04.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-01.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-05.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-11.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-08.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Comment_2016-09.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-08.csv...\n",
      "loading for ../data/Reddit data/2016/Reddit_Submission_2016-09.csv...\n"
     ]
    }
   ],
   "source": [
    "output = merge_and_clean_data(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_1 = output[output['score']>= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_1.to_csv('../data_cleaned/reddit_data_19102021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>tickers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15-09-01</td>\n",
       "      <td>US Futures pointing lower... PANIC!!!Well shuc...</td>\n",
       "      <td>14</td>\n",
       "      <td>[US, PANIC, RIP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15-09-01</td>\n",
       "      <td>Indisputable proof that the shemitah is upon u...</td>\n",
       "      <td>20</td>\n",
       "      <td>[US]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15-09-01</td>\n",
       "      <td>Dear mods, FS Comeau here with a message for y...</td>\n",
       "      <td>48</td>\n",
       "      <td>[FS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15-09-01</td>\n",
       "      <td>World markets sell off after China PMI and com...</td>\n",
       "      <td>38</td>\n",
       "      <td>[PMI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>15-09-01</td>\n",
       "      <td>Q: VXX / XIV, what's the big deal? A: it's the...</td>\n",
       "      <td>10</td>\n",
       "      <td>[VXX, XIV, VIX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6681</th>\n",
       "      <td>16-09-30</td>\n",
       "      <td>&lt;---- = # of pussies in this subreddit who pla...</td>\n",
       "      <td>623</td>\n",
       "      <td>[JNUG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>16-09-30</td>\n",
       "      <td>Is it too late to buy-in on AMD?Did I miss the...</td>\n",
       "      <td>11</td>\n",
       "      <td>[AMD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>16-09-30</td>\n",
       "      <td>Lets Start a FundIt can be called WSB on the N...</td>\n",
       "      <td>18</td>\n",
       "      <td>[JNUG, DUST, AMD, MAST, NVAX, SPY, CALLS, NUGT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>16-09-30</td>\n",
       "      <td>Building Custom Stock Alerts in Google Spreads...</td>\n",
       "      <td>52</td>\n",
       "      <td>[UBS, MBA, SMS, X, PM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>16-09-30</td>\n",
       "      <td>Nobody Talking about Nutanix?Not profitable, b...</td>\n",
       "      <td>21</td>\n",
       "      <td>[IMO, NTNX]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32326 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                               text  score  \\\n",
       "13    15-09-01  US Futures pointing lower... PANIC!!!Well shuc...     14   \n",
       "17    15-09-01  Indisputable proof that the shemitah is upon u...     20   \n",
       "29    15-09-01  Dear mods, FS Comeau here with a message for y...     48   \n",
       "33    15-09-01  World markets sell off after China PMI and com...     38   \n",
       "37    15-09-01  Q: VXX / XIV, what's the big deal? A: it's the...     10   \n",
       "...        ...                                                ...    ...   \n",
       "6681  16-09-30  <---- = # of pussies in this subreddit who pla...    623   \n",
       "6699  16-09-30  Is it too late to buy-in on AMD?Did I miss the...     11   \n",
       "6708  16-09-30  Lets Start a FundIt can be called WSB on the N...     18   \n",
       "6728  16-09-30  Building Custom Stock Alerts in Google Spreads...     52   \n",
       "6741  16-09-30  Nobody Talking about Nutanix?Not profitable, b...     21   \n",
       "\n",
       "                                              tickers  \n",
       "13                                   [US, PANIC, RIP]  \n",
       "17                                               [US]  \n",
       "29                                               [FS]  \n",
       "33                                              [PMI]  \n",
       "37                                    [VXX, XIV, VIX]  \n",
       "...                                               ...  \n",
       "6681                                           [JNUG]  \n",
       "6699                                            [AMD]  \n",
       "6708  [JNUG, DUST, AMD, MAST, NVAX, SPY, CALLS, NUGT]  \n",
       "6728                           [UBS, MBA, SMS, X, PM]  \n",
       "6741                                      [IMO, NTNX]  \n",
       "\n",
       "[32326 rows x 4 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropnas \n",
    "## remove [removed]\n",
    "## [deleted]\n",
    "## remove links \n",
    "## Remove bot messages that remove text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
