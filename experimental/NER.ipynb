{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6wGVfGVwQ5Q",
    "outputId": "66a28afa-7180-4dab-8cc3-dbaac1492cd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n",
      "Requirement already satisfied: spark-nlp in /usr/local/lib/python3.7/dist-packages (3.2.3)\n",
      "Packages installed successfully\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install spark-nlp\n",
    "import sparknlp\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.sql import SparkSession\n",
    "print('Packages installed successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nObyM6UJyjIe"
   },
   "source": [
    "Starting a sparknlp session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qfZzvQoQwPlS"
   },
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ROP0FY5vxx2K"
   },
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "No I am not gong to give you a PT. No I am not going to name a ticker that is clearly over extended and ready for the RSI to cool off. This stock is in a nice dip here and it has the potntial to move this week.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS0GoHgc15y_"
   },
   "source": [
    "Make a dataframe out of the given text to make it easier for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "KYhoQkP21pq7"
   },
   "outputs": [],
   "source": [
    "data = spark.createDataFrame([[sample_text]]).toDF('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AY798QO_7_LN",
    "outputId": "8be45fb0-6e7b-44e3-9524-ec3a742b9cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                                                                                                                                |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|\n",
      "No I am not gong to give you a PT. No I am not going to name a ticker that is clearly over extended and ready for the RSI to cool off. This stock is in a nice dip here and it has the potntial to move this week.\n",
      "|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "Xm_4dX7G1_JD",
    "outputId": "eb840e63-a712-44b6-9816-4f16aded7b94"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n1) Indicate that the input column is the dataframe containing the sample text\\n2) The output column will be named document\\n3) setCleanUpMode('shrink') is used to remove any unwanted spaces in the inputted text\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Form a document out of the given dataframe to pass it down the NER pipeline\n",
    "document = DocumentAssembler().setInputCol('text').setOutputCol('document').setCleanupMode('shrink')\n",
    "\n",
    "'''\n",
    "1) Indicate that the input column is the dataframe containing the sample text\n",
    "2) The output column will be named document\n",
    "3) setCleanUpMode('shrink') is used to remove any unwanted spaces in the inputted text\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGs-vW4O2q1u"
   },
   "source": [
    "Stage 1 - Split up the given text into its constituent sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "2pjuh2cX2CdS",
    "outputId": "dbd6031f-173b-4b86-d794-7233a309efe1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n1) Similar to the above document assembler, this line of code splits up the given sample text into its own individual rows, \\nunder the column named sentence\\n2) setExplodeSentence(True) is used to place each separate sentence in its own dataframe row\\n3) This is for efficiency purposes\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the inputted text is made up of multiple sentences, split the sentences into their own columns\n",
    "sentence = SentenceDetector().setInputCols('document').setOutputCol('sentence')\n",
    "sentence.setExplodeSentences(True)\n",
    "\n",
    "'''\n",
    "1) Similar to the above document assembler, this line of code splits up the given sample text into its own individual rows, \n",
    "under the column named sentence\n",
    "2) setExplodeSentence(True) is used to place each separate sentence in its own dataframe row\n",
    "3) This is for efficiency purposes\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoe6uidH3We2"
   },
   "source": [
    "Stage 2 - Split up each sentence into separate meaningful tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6RQz0oBR2-CT"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().setInputCols('sentence').setOutputCol('token')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIY-NLaA4KcF"
   },
   "source": [
    "Stage 3 - Correct any spelling errors (since this is reddit user data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBRl22hx3bZb",
    "outputId": "dedf77f0-4d44-4612-f70d-a6388264cde8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spellcheck_norvig download started this may take some time.\n",
      "Approximate size to download 4.2 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "checker = NorvigSweetingModel.pretrained().setInputCols(['token']).setOutputCol('checked')\n",
    "\n",
    "# Downloads a pretrained model on the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi1S44Gw4jOI"
   },
   "source": [
    "Stage 4 - Using the BERT embeddings model compared to standard one due to its ability to infer context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "n-_RgIjK4OUq",
    "outputId": "3cc1c75f-bf11-47b2-fb54-3d9002fed8be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nBert carries out bidirectional text parsing to infer context from a sentence with greater accuracy\\nOutputs the result into the embeddings column\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = WordEmbeddingsModel.pretrained().setInputCols(['sentence', 'checked']).setOutputCol('embeddings')\n",
    "\n",
    "'''\n",
    "Bert carries out bidirectional text parsing to infer context from a sentence with greater accuracy\n",
    "Outputs the result into the embeddings column\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbVT_Kw45qpQ"
   },
   "source": [
    "Stage 5 - NER stage to tag each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "9J6N8Sru4lYK",
    "outputId": "32861541-e08a-439b-ac9c-331e3b90174b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_dl download started this may take some time.\n",
      "Approximate size to download 13.6 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n1) The pretrained NER model takes in the above parameters and produces the respective taggings in the ner column\\n2) The converter then takes in the ner taggings and convert them into something meaningful we can understand using the \\nCoNLL format so that we can identify what is the meaning of each tag\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = NerDLModel.pretrained().setInputCols(['sentence', 'checked', 'embeddings']).setOutputCol('ner')\n",
    "converter = NerConverter().setInputCols(['sentence', 'checked', 'ner']).setOutputCol('chunk')\n",
    "\n",
    "'''\n",
    "1) The pretrained NER model takes in the above parameters and produces the respective taggings in the ner column\n",
    "2) The converter then takes in the ner taggings and convert them into something meaningful we can understand using the \n",
    "CoNLL format so that we can identify what is the meaning of each tag\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBAh4snv5xZI"
   },
   "source": [
    "Final stage - Forming the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "fAZTsWmY5tfS"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline().setStages([document, sentence, tokenizer, checker, embeddings, ner, converter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "X3AuydUq5zya"
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "BsN-z_KM52Iy"
   },
   "outputs": [],
   "source": [
    "result = model.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8HZ7ItL91vM"
   },
   "source": [
    "Analysing the result at each stage in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZz2ZE6h9Dsx",
    "outputId": "c796504f-2dbf-44ed-fe2d-2910a2732f2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                               |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|[No I am not gong to give you a PT.]                                                                 |\n",
      "|[No I am not going to name a ticker that is clearly over extended and ready for the RSI to cool off.]|\n",
      "|[This stock is in a nice dip here and it has the potntial to move this week.]                        |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('sentence.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JX3TySey-Pq5"
   },
   "source": [
    "Checking spell check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24eou9WU-Fe6",
    "outputId": "d2e12c6d-b714-458c-ced7-2a23a0625bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                      |\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "|[No, I, am, not, gong, to, give, you, a, PT, .]                                                                             |\n",
      "|[No, I, am, not, going, to, name, a, ticker, that, is, clearly, over, extended, and, ready, for, the, RSI, to, cool, off, .]|\n",
      "|[This, stock, is, in, a, nice, dip, here, and, it, has, the, potential, to, move, this, week, .]                            |\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('checked.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "WmdWZSK6-i36"
   },
   "outputs": [],
   "source": [
    "# As seen above, the checker managed to correct 1 of two intentionally introduced spelling errors (potntial to potential), could not fix gong to going"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jm5_XcBm_JEb"
   },
   "source": [
    "Checking the ner result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RrpQd2MV_E9i",
    "outputId": "4d166674-fdfe-4fa5-8577-779e07272646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+\n",
      "|result                                                                   |\n",
      "+-------------------------------------------------------------------------+\n",
      "|[O, O, O, O, O, O, O, O, O, B-ORG, O]                                    |\n",
      "|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG, O, O, O, O]|\n",
      "|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                   |\n",
      "+-------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('ner.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "0gntNi8jFyic"
   },
   "outputs": [],
   "source": [
    "# The model has identified the metrics of a stock, price target (PT) and RSI (Relative strength index) as beginnings of organisations. Some room for improvement here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9HstcflGdGS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NER.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
